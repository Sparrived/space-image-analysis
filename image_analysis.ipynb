{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检测 CUDA 版本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 相关库安装\n",
    "\n",
    "### 1. 使用不低于 Python3.8 的 python 版本\n",
    "\n",
    "### 2. 仅需要在新环境下运行此 cell\n",
    "\n",
    "### 3. 若 CUDA 版本小于 12.1 请修改 torch 安装版本或使用 CPU 运算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 准备工作\n",
    "\n",
    "## 1.1 导入相关库\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] # 使用SimHei字体显示中文\n",
    "plt.rcParams['axes.unicode_minus']=False   # 解决负号'-'显示为方块的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 定义相关计算函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(point1,point2):\n",
    "    \"\"\" 通过向量计算距离\n",
    "    params:\n",
    "    point1,point2 - 待计算的点，使用tuple或ndarray\n",
    "    \"\"\"\n",
    "    if isinstance(point1, tuple):\n",
    "        point1 = np.array(point1)\n",
    "    if isinstance(point2, tuple):\n",
    "        point2 = np.array(point2)\n",
    "    return np.linalg.norm(point2 - point1)\n",
    "\n",
    "def calculate_angle(point1, point2):\n",
    "    \"\"\" 通过向量计算角度\n",
    "    params:\n",
    "    point1,point2 - 待计算的点，使用tuple或ndarray\n",
    "    \"\"\"\n",
    "    if isinstance(point1, tuple):\n",
    "        point1 = np.array(point1)\n",
    "    if isinstance(point2, tuple):\n",
    "        point2 = np.array(point2)\n",
    "    dot_product = np.dot(point1, point2)\n",
    "    length1 = np.linalg.norm(point1)\n",
    "    length2 = np.linalg.norm(point2)\n",
    "    cos_angle = dot_product / (length1 * length2)\n",
    "    angle_radians = np.arccos(cos_angle)\n",
    "    angle_degrees = np.degrees(angle_radians)\n",
    "    return angle_degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 设置主要参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主要参数\n",
    "USEGPU = True  # 使用GPU进行运算\n",
    "# 读取与保存位置\n",
    "PATH_LOCS = {\n",
    "    \"INPUT\": Path(\"deeplab-resnet101-ade/input\"),  # 输入数据集的位置（指没有经过处理的图片数据）\n",
    "    \"ADE_SPLIT\": Path(\"deeplab-resnet101-ade/ade-split-output\"),  # ADE语义分割后的结果保存位置\n",
    "    \"DIS_2D\": Path(\"outputs/dis-2D-output\"),  # 经过二维分析后的结果保存位置\n",
    "    \"DEPTH\": Path(\"outputs/depth-output\"),  # 经过MiDas单目深度估计后的结果保存位置\n",
    "    \"DIS_3D\": Path(\"outputs/dis-3D-output\"),  # 经过三维分析后的结果保存位置\n",
    "    \"TEMP_DATA\": Path(\"outputs/temp-data\"),\n",
    "    \"RESULT\": Path(\"results\")  # 保存分析结果的位置\n",
    "}\n",
    "# 创建没有的文件夹\n",
    "for _, path in PATH_LOCS.items():\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"是否使用GPU运算：\", \"是\" if USEGPU else \"否\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ADE 语义分割\n",
    "\n",
    "（此处为 PyTorch 版本，仍未完成，请使用 mxnet-ade/mxnet_ade.ipynb 进行语义分割）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 准备工作\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 读取类别映射\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_f_path = Path(\"deeplab-resnet101-ade/type_f.json\")\n",
    "\n",
    "if type_f_path.exists():\n",
    "    with open(type_f_path, 'r', encoding=\"utf8\") as file:\n",
    "        col_map = json.load(file)\n",
    "        if col_map:\n",
    "            print(f\"读取 type_f.json 成功！获取了 {len(col_map)} 条映射数据.\")\n",
    "else:\n",
    "    print(f\"type_f.json 不存在！请检查文件结构.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 (废弃)定义运算的相关函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_mask_on_image(original_img_path, mask, output_folder, filename):\n",
    "    original_img = Image.open(original_img_path)\n",
    "    mask_img = mask.convert(\"RGBA\")\n",
    "    overlayed_img = Image.blend(original_img.convert(\"RGBA\"), mask_img, 0.5)  # 调整遮罩透明度\n",
    "    overlay_filename = filename.stem + '_overlay.png'\n",
    "    overlay_path = output_folder / overlay_filename\n",
    "    overlayed_img.save(overlay_path)\n",
    "    return overlay_filename\n",
    "\n",
    "\n",
    "def calculate_percentage(counts, total_pixels):\n",
    "    return [count / total_pixels * 100 for count in counts]\n",
    "\n",
    "\n",
    "def collect_segmentation_data(predict, col_map):\n",
    "    unique_elements, counts_elements = np.unique(predict, return_counts=True)\n",
    "    total_pixels = sum(counts_elements)\n",
    "    counts_percentage = calculate_percentage(counts_elements, total_pixels)\n",
    "    data = {col_map.get(k, 'Unknown'): v for k, v in zip(unique_elements, counts_percentage)}\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_segmentation_stats_to_csv(data, output_folder, filename):\n",
    "    df = pd.DataFrame([data])\n",
    "    output_filename_csv = filename.stem + '_segmentation_stats.csv'\n",
    "    save_path_csv = output_folder / output_filename_csv\n",
    "    df.to_csv(save_path_csv, index=False)\n",
    "    return output_filename_csv\n",
    "\n",
    "\n",
    "def auto_adjust_chart_size(df):\n",
    "    size = max(10, len(df.columns) / 2)\n",
    "    return size\n",
    "\n",
    "\n",
    "def save_visualization_chart(data, output_folder, filename):\n",
    "    df = pd.DataFrame([data]).rename(columns=col_map)\n",
    "    df = df.loc[:, df.sum() > 1]\n",
    "    df['其他'] = 100 - df.sum(axis=1)\n",
    "    chart_size = auto_adjust_chart_size(df)\n",
    "    plt.figure(figsize=(chart_size, 6))\n",
    "    df.T.plot(kind='bar', legend=False, width=0.8)\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    plt.title(f'Segmentation Percentages for {filename.name}')\n",
    "    plt.xticks(rotation=0)  # 确保x轴标签名称横向显示\n",
    "    chart_filename = filename.stem + '_visualization_chart.png'\n",
    "    save_path_chart = output_folder / chart_filename\n",
    "    plt.savefig(save_path_chart)\n",
    "    plt.cla()\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "def compile_and_plot_segmentation_trends(segmentation_data, output_folder):\n",
    "    df_compiled = pd.DataFrame(segmentation_data).T.rename(columns=col_map).fillna(0)\n",
    "    mean_percentages = df_compiled.mean()\n",
    "    significant_categories = mean_percentages[mean_percentages > 1].index\n",
    "    df_compiled = df_compiled[significant_categories]\n",
    "    plt.figure(figsize=(max(12, len(segmentation_data) * 0.5), 8))\n",
    "    for column in df_compiled.columns:\n",
    "        plt.plot(df_compiled.index, df_compiled[column], marker='o', label=column)\n",
    "    plt.xlabel('图片索引')\n",
    "    plt.ylabel('像素百分比')\n",
    "    plt.title('Segmentation Trends Across Images')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "    trends_filename = 'segmentation_trends.png'\n",
    "    plt.savefig(output_folder / trends_filename)\n",
    "    plt.cla()\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "def segment_images(input_folder, output_folder, model, ctx) -> int:\n",
    "    segmentation_data = {}\n",
    "    for filename in tqdm(sorted(os.listdir(input_folder))):\n",
    "        if filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "            # 读取图片并归一化\n",
    "            img_path = input_folder / Path(filename)\n",
    "            img = image.imread(img_path)\n",
    "            img = test_transform(img, ctx=ctx)\n",
    "            # 进行预测\n",
    "            output = model.predict(img)\n",
    "            predict = mx.nd.squeeze(mx.nd.argmax(output, 1)).asnumpy()\n",
    "            # 将所有判断为房屋的位置改为建筑，保持一致性\n",
    "            predict[predict == 25] = 1\n",
    "            # 创建遮罩\n",
    "            mask = get_color_pallete(predict, 'ade')\n",
    "            # 保存遮罩\n",
    "            output_filename = filename.stem + '_seg_ade_101.png'\n",
    "            save_path = output_folder / output_filename\n",
    "            mask.save(save_path)\n",
    "            # 透明化遮罩并覆盖到原图\n",
    "            overlay_mask_on_image(img_path, mask, output_folder, img_path)\n",
    "            # 统计图片内色块数据\n",
    "            data = collect_segmentation_data(predict, col_map)\n",
    "            save_segmentation_stats_to_csv(data, output_folder, img_path)\n",
    "            save_visualization_chart(data, output_folder, img_path)\n",
    "            segmentation_data[filename] = data\n",
    "    # 保存像素百分比的条带\n",
    "    compile_and_plot_segmentation_trends(segmentation_data, output_folder)\n",
    "    return len(segmentation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 图片处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 载入模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ade_model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet101', pretrained=True)\n",
    "# or any of these variants\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_mobilenet_v3_large', pretrained=True)\n",
    "ade_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 使用 ADE 数据集对图片进行分割并处理相关数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "print(\"使用 PyTorch 进行图片语义分割.\")\n",
    "input_image = Image.open(PATH_LOCS['INPUT'] / \"1.jpg\")\n",
    "input_image = input_image.convert(\"RGB\")\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    ade_model.to('cuda')\n",
    "with torch.no_grad():\n",
    "    output = ade_model(input_batch)['out'][0]\n",
    "output_predictions = output.argmax(0)\n",
    "# create a color pallette, selecting a color for each class\n",
    "palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
    "colors = torch.as_tensor([i for i in range(21)])[:, None] * palette\n",
    "colors = (colors % 255).numpy().astype(\"uint8\")\n",
    "# plot the semantic segmentation predictions of 21 classes in each color\n",
    "r = Image.fromarray(output_predictions.byte().cpu().numpy()).resize(input_image.size)\n",
    "r.putpalette(colors)\n",
    "plt.imshow(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 二维视角的图片处理与分析\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 准备工作\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 定义文件位置与颜色映射\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理后图片的文件位置\n",
    "file_list = list(filter(lambda x: \"seg_ade_101\" in x, sorted(os.listdir(PATH_LOCS[\"ADE_SPLIT\"]))))\n",
    "# 颜色映射\n",
    "color_mapping = {\n",
    "    (0,0,128): \"树\",\n",
    "    (0,128,0): \"天空\",\n",
    "    (128,0,0): \"建筑\",\n",
    "    (128,64,128): \"水\",\n",
    "    (128,64,0): \"植物\",\n",
    "    (0,128,64): \"岩石\",\n",
    "    (192,64,0): \"房子\"\n",
    "}\n",
    "# 读取颜色映射中存在的颜色\n",
    "valid_colors = list(color_mapping.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 定义相关类存储数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Collection:\n",
    "    \"\"\" 存储质心和质心对应的框所在位置\n",
    "    centroid(tuple) - 质心的位置（2D）\n",
    "    stat(ndarray) - 质心对应所在位置([x,y,长,宽,面积])\n",
    "    \"\"\"\n",
    "    centroid : tuple\n",
    "    stat : ndarray\n",
    "\n",
    "@dataclass\n",
    "class SplitImg2D:\n",
    "    \"\"\" 存储语义分割后的二维图片数据\n",
    "    filename(str) - 文件名\n",
    "    color_centers(dict[tuple, list[Collection]]) - 该图片中的各色快的信息\n",
    "    \"\"\"\n",
    "    filename : str\n",
    "    color_centers : 'dict[tuple, list[Collection]]'\n",
    "\n",
    "    def get_ade_image(self):\n",
    "        \"\"\"获取ade处理后的图片\"\"\"\n",
    "        image = cv2.imread(PATH_LOCS[\"ADE_SPLIT\"] / self.filename)\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    def get_origin_image(self):\n",
    "        \"\"\"获取源图片\"\"\"\n",
    "        image =  cv2.imread(PATH_LOCS[\"INPUT\"] / (self.filename.split(\"_\")[0] + \".jpg\"))\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 图片处理\n",
    "\n",
    "### 3.2.1 计算各色快的质心并将图片打包存储\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储分割的图片对象\n",
    "split_images_2d : 'list[SplitImg2D]' = []\n",
    "for filename in tqdm(file_list):\n",
    "    # 读取图片\n",
    "    image = cv2.imread(PATH_LOCS[\"ADE_SPLIT\"] / filename)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # 找到图像中的所有唯一颜色\n",
    "    unique_colors = np.unique(image.reshape(-1, image.shape[2]), axis=0)\n",
    "    # 存储每一个色块的中心\n",
    "    color_centers = defaultdict(list)\n",
    "    # 遍历每个颜色，分割色块并计算其几何中心\n",
    "    for color in unique_colors:\n",
    "        if tuple(color) in valid_colors:\n",
    "            # 创建一个遮罩，找到所有相同颜色的像素\n",
    "            mask = cv2.inRange(image, color, color)\n",
    "            # 通过连通性分离各色快\n",
    "            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask)\n",
    "            # 去除第一个作为背景的色块\n",
    "            centroids = centroids[1:]\n",
    "            stats = stats[1:]\n",
    "            #筛选合理的色块，去除太小的部分\n",
    "            threshold_area = 900  # 设置阈值\n",
    "            valid_labels = np.where(stats[:, cv2.CC_STAT_AREA] > threshold_area)[0]\n",
    "            # 在color_centers字典中保存质点与质点对应的框\n",
    "            for i in valid_labels:\n",
    "                color_centers[tuple(color)].append(Collection(tuple(list(map(int,centroids[i]))), stats[i]))\n",
    "    split_images_2d.append(SplitImg2D(filename, color_centers))\n",
    "print(\"成功存储\", len(split_images_2d), \"份图片数据.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 （可选）存档图片数据\n",
    "\n",
    "可以通过存档图片数据，后续无需再跑一次前面的步骤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = str(time.time()) + \".pkl\"\n",
    "with open(PATH_LOCS[\"TEMP_DATA\"] / fname, 'wb') as f:\n",
    "    pickle.dump(split_images_2d, f)\n",
    "print(\"图片信息已保存在\", f\"outputs/temp-data/{fname} 中.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 图片分析\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 （可选）读取图片数据\n",
    "\n",
    "[重要]需要将 FNAME2D 改为图片数据的文件名\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNAME2D = \"1721400572.4975064.pkl\"\n",
    "\n",
    "with open(PATH_LOCS['TEMP_DATA'] / FNAME2D, 'rb') as f:\n",
    "    split_images_2d : 'list[SplitImg2D]' = pickle.load(f)\n",
    "    if split_images_2d:\n",
    "        print(\"已读取\", len(split_images_2d), \"条图片数据.\")\n",
    "    else:\n",
    "        print(\"文件读取失败，请重试或重新生成文件.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 在原图中绘制质心\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_image in tqdm(split_images_2d):\n",
    "    image = split_image.get_origin_image()\n",
    "    for color, collections in split_image.color_centers.items():\n",
    "        color = tuple(map(int, color))\n",
    "        for collection in collections:\n",
    "            center = collection.centorid\n",
    "            stat = collection.stat\n",
    "            # 绘制矩形\n",
    "            cv2.rectangle(image, (stat[0],stat[1]), (stat[0]+stat[2],stat[1]+stat[3]), color=color)\n",
    "            # 绘制点\n",
    "            cv2.circle(image, center, 8, color=color, thickness=-1)\n",
    "            # 标注字\n",
    "            fontpath = \"./simsun.ttc\"\n",
    "            font = ImageFont.truetype(fontpath, 16)\n",
    "            img_pil = Image.fromarray(image)\n",
    "            draw = ImageDraw.Draw(img_pil)\n",
    "            draw.text((center[0] + 10, center[1] + 10),  f\"{color_mapping[tuple(color)]}\", font = font, fill = (255,255,255))\n",
    "            image = np.array(img_pil)\n",
    "    plt.imsave(PATH_LOCS[\"DIS_2D\"] / (split_image.filename.split(\"_\")[0] + \"_2d_distance.png\"), image)\n",
    "print(\"质心图绘制成功，共\", len(split_images_2d), \"张，全部保存在outputs/dis-2D-output下.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 二维视角的距离和角度分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_count = 0\n",
    "for image_split in tqdm(split_images_2d):\n",
    "    image = image_split.get_ade_image()\n",
    "    x, y, _ = image.shape\n",
    "    long = max(x,y)\n",
    "    # 保存xy坐标和颜色值\n",
    "    x = []\n",
    "    y = []\n",
    "    colors = []\n",
    "    # 创建fig\n",
    "    fig = plt.figure()\n",
    "    ax = fig.subplots()\n",
    "    # 设置坐标轴标签\n",
    "    ax.set_xlabel('横向像素')\n",
    "    ax.set_ylabel('纵向像素', rotation=90)\n",
    "    # 读取图片信息\n",
    "    for color, collections in image_split.color_centers.items():\n",
    "        for collection in collections:\n",
    "            center = collection.centorid\n",
    "            x.append(center[0])\n",
    "            y.append(long - center[1])\n",
    "            colors.append(color)\n",
    "    groups = {}\n",
    "    datas = []\n",
    "    # 色块分组\n",
    "    for i, color in enumerate(colors):\n",
    "        if color not in groups:\n",
    "            groups[color] = []\n",
    "        groups[color].append((x[i], y[i]))\n",
    "    try:\n",
    "        building_group = groups[(128,0,0)]\n",
    "    except:\n",
    "        print(\"图片\", image_split.filename.split('_')[0], \"没有建筑色块，已忽略.\")\n",
    "        ignore_count += 1\n",
    "        continue\n",
    "    #对色块的每一个点进行分析\n",
    "    for color, points in groups.items():\n",
    "        x, y = zip(*points)\n",
    "        ax.scatter(x, y, c=[np.array(color)/255], label=color_mapping[color])\n",
    "        if color_mapping[color] != \"建筑\":\n",
    "            for i in range(len(x)):\n",
    "                for j in range(len(building_group)):\n",
    "                    ax.plot([x[i], building_group[j][0]], [y[i], building_group[j][1]], 'b--')\n",
    "                    dis = calculate_distance((x[i],y[i]), building_group[j])\n",
    "                    angle = calculate_angle(building_group[j], (x[i],y[i]))\n",
    "                    data = {\n",
    "                        \"图片ID\": image_split.filename.split(\"_\")[0],\n",
    "                        \"要素类型\":color_mapping[color],\n",
    "                        \"要素流向\": f\"{color_mapping[color]}-建筑\",\n",
    "                        \"要素位置\": f\"({x[i]},{y[i]})\",\n",
    "                        \"建筑位置\": f\"({building_group[j][0]}, {building_group[j][1]})\",\n",
    "                        \"距离\": dis,\n",
    "                        \"角度\": angle\n",
    "                        }\n",
    "                    datas.append(data)\n",
    "        else:\n",
    "            for i in range(len(x)):\n",
    "                for j in range(len(x)):\n",
    "                    if i == j:\n",
    "                        break\n",
    "                    ax.plot([x[i], x[j]], [y[i], y[j]], 'r--')\n",
    "\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    # print(datas)\n",
    "    # 保存数据和图片\n",
    "    fig.savefig(PATH_LOCS[\"DIS_2D\"] / ((str(image_split.filename.split('_')[0])) + \"_2d_plot.png\"))\n",
    "    df = pd.DataFrame(datas)\n",
    "    df.to_excel(PATH_LOCS[\"DIS_2D\"] / ((str(image_split.filename.split('_')[0])) + \"_2d_data.xlsx\"))\n",
    "    plt.cla()\n",
    "    plt.close('all')\n",
    "print(\"已成功处理\", len(split_images_2d)-ignore_count, \"张图片得到相关数据.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 汇总二维数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list = list(filter(lambda x: \"2d_data\" in x, sorted(os.listdir(PATH_LOCS[\"DIS_2D\"]))))\n",
    "DFs = [pd.read_excel(PATH_LOCS[\"DIS_2D\"] / f, engine=\"openpyxl\") for f in tqdm(f_list)]\n",
    "concat_data = pd.concat(DFs)\n",
    "concat_data.to_excel(PATH_LOCS[\"RESULT\"] / \"2d_results.xlsx\", index=False)\n",
    "print(\"已成功汇总二维数据，保存在\",PATH_LOCS[\"RESULT\"] / \"2d_results.xlsx\", \"下.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5 使用 DBSCAN 进行聚类分析\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二维距离\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取Excel文件\n",
    "data = pd.read_excel(PATH_LOCS[\"RESULT\"] / \"2d_results.xlsx\", engine=\"openpyxl\")\n",
    "# 提取不同的要素流向\n",
    "flow_directions = data['要素流向'].unique()\n",
    "# 准备存储聚类结果的列表\n",
    "results = []\n",
    "# 对每个要素点分别进行聚类\n",
    "for direction in tqdm(flow_directions):\n",
    "    # 提取当前要素流向的数据\n",
    "    subset = data[data['要素流向'] == direction]\n",
    "    directions = np.array(subset[\"距离\"])\n",
    "    directions = directions.reshape(-1, 1)\n",
    "  \n",
    "    db = DBSCAN(eps=1, min_samples=30).fit(directions)\n",
    "    labels = db.labels_\n",
    "    subset['聚类标签'] = labels\n",
    "    # 计算密度\n",
    "    unique_labels = set(labels)\n",
    "    densities = np.zeros_like(labels, dtype=float)\n",
    "    \n",
    "    for k in unique_labels:\n",
    "        if k != -1:\n",
    "            # 计算每个聚类的密度\n",
    "            class_member_mask = (labels == k)\n",
    "            densities[class_member_mask] = np.sum(class_member_mask) / len(directions)\n",
    "    \n",
    "    # 绘制直线图\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    \n",
    "    # 创建颜色映射\n",
    "    norm = Normalize(vmin=min(densities), vmax=max(densities))\n",
    "    cmap = plt.get_cmap('Spectral')\n",
    "    sm = ScalarMappable(norm=norm, cmap=cmap)\n",
    "    \n",
    "    # 为每个点绘制一条直线\n",
    "    for i in range(len(directions)):\n",
    "        plt.plot([directions[i], directions[i]], [0, densities[i]], color=sm.to_rgba(densities[i]), lw=2)\n",
    "    \n",
    "    plt.title(f'DBSCAN 聚类-{direction} | 距离 (eps=1, 最小样本数=30)')\n",
    "    plt.xlabel('像素距离')\n",
    "    plt.yticks([])  # 隐藏y轴刻度\n",
    "    \n",
    "    # 添加颜色条\n",
    "    cbar = plt.colorbar(sm, orientation='vertical')\n",
    "    cbar.set_label('密度')\n",
    "    \n",
    "    plt.savefig(PATH_LOCS[\"RESULT\"]/ f'DBSCAN聚类-{direction}-距离.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "角度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对每个要素点分别进行聚类\n",
    "for direction in tqdm(flow_directions):\n",
    "    # 提取当前要素流向的数据\n",
    "    subset = data[data['要素流向'] == direction]\n",
    "    directions = np.array(subset[\"角度\"])\n",
    "    directions = np.nan_to_num(directions, nan=0).reshape(-1, 1)\n",
    "    \n",
    "    db = DBSCAN(eps=0.1, min_samples=50).fit(directions)\n",
    "    labels = db.labels_\n",
    "    subset['聚类标签'] = labels\n",
    "    # 计算密度\n",
    "    unique_labels = set(labels)\n",
    "    densities = np.zeros_like(labels, dtype=float)\n",
    "    \n",
    "    for k in unique_labels:\n",
    "        if k != -1:\n",
    "            # 计算每个聚类的密度\n",
    "            class_member_mask = (labels == k)\n",
    "            densities[class_member_mask] = np.sum(class_member_mask) / len(directions)\n",
    "    \n",
    "    # 绘制直线图\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    \n",
    "    # 创建颜色映射\n",
    "    norm = Normalize(vmin=min(densities), vmax=max(densities))\n",
    "    cmap = plt.get_cmap('Spectral')\n",
    "    sm = ScalarMappable(norm=norm, cmap=cmap)\n",
    "    \n",
    "    # 为每个点绘制一条直线\n",
    "    for i in range(len(directions)):\n",
    "        plt.plot([directions[i], directions[i]], [0, densities[i]], color=sm.to_rgba(densities[i]), lw=2)\n",
    "    \n",
    "    plt.title(f'DBSCAN 聚类-{direction} | 角度 (eps=0.1, 最小样本数=50)')\n",
    "    plt.xlabel('角度')\n",
    "    plt.yticks([])  # 隐藏y轴刻度\n",
    "    # 添加颜色条\n",
    "    cbar = plt.colorbar(sm, orientation='vertical')\n",
    "    cbar.set_label('密度')\n",
    "    \n",
    "    plt.savefig(PATH_LOCS[\"RESULT\"]/ f'DBSCAN聚类-{direction}-角度.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（废弃）二维点的聚类\n",
    "这个聚类结果看不出关系\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# 读取Excel文件\n",
    "data = pd.read_excel(PATH_LOCS[\"RESULT\"] / \"2d_results.xlsx\", engine=\"openpyxl\")\n",
    "\n",
    "# 提取不同的要素流向\n",
    "flow_directions = data['要素流向'].unique()\n",
    "\n",
    "# 准备存储聚类结果的列表\n",
    "results = []\n",
    "\n",
    "def batch_data(data, batch_size):\n",
    "    for start in range(0, len(data), batch_size):\n",
    "        yield data[start:start + batch_size]\n",
    "\n",
    "\n",
    "# 对每个要素点分别进行聚类\n",
    "for direction in tqdm(flow_directions):\n",
    "    # 提取当前要素流向的数据\n",
    "    subset = data[data['要素流向'] == direction]\n",
    "\n",
    "    \n",
    "    \n",
    "    points = subset['要素位置'].values\n",
    "    points = np.array(list(map(list, map(eval, points))))\n",
    "    # 计算成对距离\n",
    "    dist_matrix = pdist(points, metric='euclidean')\n",
    "\n",
    "    # 将成对距离转换为方阵形式\n",
    "    dist_matrix_square = squareform(dist_matrix)\n",
    "    \n",
    "    db = DBSCAN(eps=24, min_samples=4, metric='precomputed').fit(dist_matrix_square)\n",
    "    labels = db.labels_\n",
    "    subset['聚类标签'] = labels\n",
    "    x = points.T[0]\n",
    "    y = points.T[1]\n",
    "    plt.scatter(x, y, c=subset['聚类标签'], cmap='viridis')\n",
    "    plt.xlabel('横向像素')\n",
    "    plt.ylabel('纵向像素')\n",
    "    plt.title(f'DBSCAN聚类结果 - {direction}')\n",
    "    plt.show()\n",
    "    # plt.savefig(str(time.time()) + \".png\")\n",
    "    # 将当前要素流向的所有聚类结果保存到results列表\n",
    "    results.append(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 三维视角下的图片处理与距离分析\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 准备工作\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 读取二维数据结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME2D = \"1721400572.4975064.pkl\"\n",
    "\n",
    "with open(PATH_LOCS[\"TEMP_DATA\"] / FILENAME2D, 'rb') as f:\n",
    "    split_images_2d : 'list[SplitImg2D]' = pickle.load(f)\n",
    "    if split_images_2d:\n",
    "        print(\"已读取二维图片信息\", len(split_images_2d), \"份.\")\n",
    "    else:\n",
    "        print(\"读取二维图片信息失败.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 图片处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 获取 MiDas 模型\n",
    "\n",
    "@article{Ranftl2020,\n",
    "author = {Ren\\'{e} Ranftl and Katrin Lasinger and David Hafner and Konrad Schindler and Vladlen Koltun},\n",
    "title = {Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer},\n",
    "journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},\n",
    "year = {2020},\n",
    "}\n",
    "\n",
    "@article{Ranftl2021,\n",
    "author = {Ren\\'{e} Ranftl and Alexey Bochkovskiy and Vladlen Koltun},\n",
    "title = {Vision Transformers for Dense Prediction},\n",
    "journal = {ArXiv preprint},\n",
    "year = {2021},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载并加载预训练的MiDaS模型\n",
    "model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
    "#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
    "#model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
    "    transform = midas_transforms.dpt_transform\n",
    "else:\n",
    "    transform = midas_transforms.small_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 （可选）移动至 GPU 运算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USEGPU:\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "midas.to(device)\n",
    "midas.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 进行单目深度估计\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tqdm(os.listdir(PATH_LOCS['INPUT'])):\n",
    "    \n",
    "    img = cv2.imread(PATH_LOCS['INPUT'] / Path(filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    input_batch = transform(img).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = midas(input_batch)\n",
    "\n",
    "        prediction = torch.nn.functional.interpolate(\n",
    "            prediction.unsqueeze(1),\n",
    "            size=img.shape[:2],\n",
    "            mode=\"bicubic\",\n",
    "            align_corners=False,\n",
    "        ).squeeze()\n",
    "    output = prediction.cpu().numpy()\n",
    "    plt.imsave(PATH_LOCS['DEPTH'] / (filename.split(\".\")[0] + \"_depth.png\"), output, cmap='viridis')\n",
    "    np.savetxt(PATH_LOCS['DEPTH'] / (filename.split(\".\")[0] + \"_depth.csv\"), output, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 图片分析\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 读取中心点对应的像素深度并制图，保存相关数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_info in tqdm(split_images_2d):\n",
    "    depth_file = PATH_LOCS['DEPTH'] / (image_info.filename.split('_')[0] + \"_depth.csv\")\n",
    "    image_split = cv2.imread(PATH_LOCS['ADE_SPLIT'] / image_info.filename)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    colors = []\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    # 设置坐标轴标签\n",
    "    ax.set_xlabel('横向像素',rotation=-20)\n",
    "    ax.set_ylabel('相对深度', rotation=50)\n",
    "    ax.set_zlabel('纵向像素', rotation=90)\n",
    "\n",
    "    with open(depth_file, 'r') as f:\n",
    "        depth_list = list(csv.reader(f))\n",
    "    for color, collections in image_info.color_centers.items():\n",
    "\n",
    "        for collection in collections:\n",
    "            center = collection.centorid\n",
    "            # print(color, center)\n",
    "            x.append(center[0])\n",
    "            y.append(center[1])\n",
    "            # 计算对应区域的平均深度\n",
    "            image = copy.deepcopy(image_split)\n",
    "            x1, y1 = collection.stat[0], collection.stat[1]\n",
    "            x2, y2 = x1 + collection.stat[2], y1 + collection.stat[3]\n",
    "            crop_image = image[y1: y2, x1 : x2]\n",
    "            image_rgb = cv2.cvtColor(crop_image, cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.inRange(image_rgb, np.array(color), np.array(color))\n",
    "            positions = np.column_stack(np.where(mask > 0))\n",
    "            positions[:, 0] += y1\n",
    "            positions[:, 1] += x1\n",
    "            #计算平均像素深度\n",
    "            total_depth = 0\n",
    "            for pos in positions:\n",
    "                total_depth += float(depth_list[pos[0]][pos[1]])\n",
    "            average_depth = total_depth / positions.size / 2\n",
    "            z.append(average_depth)\n",
    "            colors.append(color)\n",
    "\n",
    "    groups = {}\n",
    "    datas = []\n",
    "    for i, color in enumerate(colors):\n",
    "        if color not in groups:\n",
    "            groups[color] = []\n",
    "        groups[color].append((x[i], y[i], z[i]))\n",
    "    try:\n",
    "        building_group = groups[(128,0,0)]\n",
    "    except:\n",
    "        print(\"image\", image_info.filename.split('_')[0], \"has no building color blocks.\")\n",
    "        continue\n",
    "    for color, points in groups.items():\n",
    "        x, y, z = zip(*points)\n",
    "        ax.scatter(y, z, x, c=[np.array(color)/255], label=color_mapping[color])\n",
    "        if color_mapping[color] != \"建筑\":\n",
    "            for i in range(len(x)):\n",
    "                for j in range(len(building_group)):\n",
    "                    ax.plot([y[i], building_group[j][1]], [z[i], building_group[j][2]], [x[i], building_group[j][0]], 'b--')\n",
    "                    dis = calculate_distance((x[i],y[i],z[i]), building_group[j])\n",
    "                    data = {\n",
    "                        \"要素类型\":color_mapping[color],\n",
    "                        \"要素流向\": f\"{color_mapping[color]}-建筑\",\n",
    "                        \"要素位置\": f\"{x[i]},{y[i]},{z[i]}\",\n",
    "                        \"建筑位置\": f\"{building_group[j][0]}, {building_group[j][1]}, {building_group[j][2]}\",\n",
    "                        \"距离\": dis\n",
    "                        }\n",
    "                    datas.append(data)\n",
    "        else:\n",
    "            for i in range(len(x)):\n",
    "                for j in range(len(x)):\n",
    "                    if i == j:\n",
    "                        break\n",
    "                    ax.plot([y[i], y[j]], [z[i], z[j]], [x[i], x[j]], 'r--')\n",
    "    ax.legend(bbox_to_anchor=(1, 0), loc=3, borderaxespad=0)\n",
    "    # print(datas)\n",
    "    # 保存数据和图片\n",
    "    fig.savefig(PATH_LOCS['DIS_3D'] / ((str(image_info.filename.split('_')[0])) + \"_3d_plot.png\"))\n",
    "    df = pd.DataFrame(datas)\n",
    "    df.to_excel(PATH_LOCS['DIS_3D'] / ((str(image_info.filename.split('_')[0])) + \"_3d_data.xlsx\"))\n",
    "    plt.cla()\n",
    "    plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
